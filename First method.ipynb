{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chang\\.conda\\envs\\ebay\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import re\n",
    "# import spacy\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as T\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from emoji import UNICODE_EMOJI\n",
    "from util import *\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "file_path = ''\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", dtype=str, keep_default_na=False, na_values=[\"\"], quoting=csv.QUOTE_NONE)\n",
    "\n",
    "from dateutil.parser import parse\n",
    "\n",
    "\n",
    "wv_from_bin = load_embedding_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what the dataset for testing looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record Number</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LOUIS VUITTON M40096 Handbag Priscilla Multi-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LOUIS VUITTON Petit Noe Drawstring Shoulder Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>LOUIS VUITTON Damier Azur Pochette Bosphore Sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>GUCCI Bamboo 2Way Shoulder Bag Leather Brown A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Rank AB Vintage Gucci Sherry line PVC Leather ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Record Number                                              Title\n",
       "0             1  LOUIS VUITTON M40096 Handbag Priscilla Multi-c...\n",
       "1             2  LOUIS VUITTON Petit Noe Drawstring Shoulder Ba...\n",
       "2             3  LOUIS VUITTON Damier Azur Pochette Bosphore Sh...\n",
       "3             4  GUCCI Bamboo 2Way Shoulder Bag Leather Brown A...\n",
       "4             5  Rank AB Vintage Gucci Sherry line PVC Leather ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_path = 'Listing_Titles.tsv'\n",
    "df_title = pd.read_csv(title_path, sep=\"\\t\", dtype=str, keep_default_na=False, na_values=[\"\"], quoting=csv.QUOTE_NONE)\n",
    "df_title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\r"
     ]
    }
   ],
   "source": [
    "#Extrat info \n",
    "titles_x = []\n",
    "vocab = set()\n",
    "MAX_LEN = 0 \n",
    "for index, row in df_title.iterrows():\n",
    "    print(index,end='\\r')\n",
    "    sent_list = row['Title'].split(' ')\n",
    "    MAX_LEN = max(MAX_LEN, len(sent_list))\n",
    "    vocab.update(sent_list)\n",
    "    if index== 30000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55121\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna('NAN')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract training info\n",
    "x = []\n",
    "y = []\n",
    "for i in range(1,5001):\n",
    "    temp_df = df[df['Record Number']==str(i)]\n",
    "    tokens = []\n",
    "    tages = []\n",
    "    \n",
    "    for index, row in temp_df.iterrows():\n",
    "        if row['Tag'] == 'NAN':\n",
    "            tokens.append(row['Token'])\n",
    "            tages.append(temp)\n",
    "        else:\n",
    "            temp =  row['Tag']\n",
    "            tokens.append(row['Token'])\n",
    "            tages.append(row['Tag'])\n",
    "\n",
    "    vocab.update(tokens)\n",
    "    \n",
    "    # doc = nlp(sentence)\n",
    "    # sentence = doc._.outcome_spellCheck\n",
    "    # tokens = sentence.split(' ')\n",
    "    x.append(tokens)\n",
    "    y.append(tages)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "# LENGTH OF THE TRAINING SET \n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# MAXIMUM LENGTH OF A SENTENCE\n",
    "MAX_LEN = 0 \n",
    "for i in x:\n",
    "    MAX_LEN = max(len(i), MAX_LEN)\n",
    "MAX_LEN +=20\n",
    "\n",
    "print(MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.0\n",
      "33.0\n"
     ]
    }
   ],
   "source": [
    "# NUMBER OF TAGS  IS 32. \n",
    "\n",
    "#Digitize the tags\n",
    "target = set()\n",
    "for i in y:\n",
    "    target.update(i)\n",
    "    \n",
    "target_name_to_index = {}\n",
    "num = 1\n",
    "for i in target:\n",
    "    target_name_to_index[i]= num\n",
    "    target_name_to_index[num]= i\n",
    "    num+=1\n",
    "print(len(target_name_to_index)/2)\n",
    "target_name_to_index[0] = '[PAD]'\n",
    "target_name_to_index['[PAD]'] = 0\n",
    "print(len(target_name_to_index)/2)\n",
    "CAT_NUM = int(len(target_name_to_index)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the dimensions of the vocabulary dimensions. \n",
    "\n",
    "#### Turns out, the higher the dimension the better. No need to reduce dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.25904993 0.81696325 0.57668452 0.25574459 0.21345183 0.15410183\n",
      " 0.1426699  0.11696192 0.09043778 0.08492469 0.08379914 0.0748369\n",
      " 0.06838907 0.06524872 0.05731288 0.05542911 0.05328101 0.05245867\n",
      " 0.04880456 0.04848949 0.04721909 0.04436738 0.04341708 0.04113247\n",
      " 0.04021009 0.03872008 0.03814719 0.03545287 0.03519026 0.03386438\n",
      " 0.03261184 0.03243122 0.03158918 0.03116499 0.03074222 0.03045423\n",
      " 0.02936531 0.02870041 0.02803693 0.02784922 0.02665729 0.02640964\n",
      " 0.0257897  0.0250006  0.02485081 0.02470358 0.02410539 0.02393676\n",
      " 0.02357152 0.02328479 0.0229408  0.02257665 0.02227422 0.02200488\n",
      " 0.02187531 0.02128517 0.02122395 0.02084136 0.0205761  0.02056401\n",
      " 0.02025064 0.02019144 0.01972388 0.01969708 0.0193217  0.01915814\n",
      " 0.01890876 0.01879868 0.01857613 0.01840255 0.01827743 0.01823555\n",
      " 0.01784731 0.01768508 0.01743104 0.017356   0.01720512 0.0171467\n",
      " 0.01702054 0.01690613 0.01664256 0.01652421 0.01640125 0.01634522\n",
      " 0.016236   0.01620508 0.01602268 0.01593267 0.01585618 0.01577801\n",
      " 0.01564377 0.01559884 0.01545926 0.01533872 0.01517285 0.01511561\n",
      " 0.0150486  0.01491588 0.01485466 0.01477393 0.01468682 0.01462957\n",
      " 0.01439917 0.01433528 0.0141991  0.0141014  0.0139706  0.01389797\n",
      " 0.01379155 0.01371785 0.01365737 0.01363094 0.01358201 0.01352039\n",
      " 0.01346889 0.01341915 0.01326504 0.01320702 0.01314494 0.01301252\n",
      " 0.01294542 0.01292449 0.0128517  0.01280038 0.01272055 0.01270277\n",
      " 0.01260535 0.01252837 0.01242529 0.01235719 0.01233205 0.01228134\n",
      " 0.01222562 0.01220521 0.01209061 0.01202345 0.01196659 0.01187764\n",
      " 0.0118222  0.01178862 0.01174785 0.01169718 0.01165154 0.01161851\n",
      " 0.01157442 0.01154295 0.01144398 0.01139714 0.01137766 0.0113266\n",
      " 0.01126456 0.01121658 0.01113627 0.01108388 0.01106981 0.01093837\n",
      " 0.01092589 0.01085006 0.01079038 0.01077354 0.01071874 0.0106782\n",
      " 0.01065144 0.01059935 0.01058447 0.0105214  0.01044558 0.01041477\n",
      " 0.01039683 0.01038102 0.01032426 0.01028567 0.01022411 0.01014116\n",
      " 0.01010282 0.01006593 0.01002478 0.01000154 0.00996446 0.00993476\n",
      " 0.00990512 0.00982494 0.00978724 0.00975869 0.0096932  0.00967645\n",
      " 0.00963584 0.0095749  0.00956892 0.00950985 0.00949468 0.00942817\n",
      " 0.00940941 0.00936661 0.00934191 0.00930745 0.00928646 0.00925245\n",
      " 0.00920254 0.00917456 0.00913772 0.00912562 0.00906745 0.00904006\n",
      " 0.00899388 0.00895599 0.00891931 0.00887448 0.00886679 0.00880143\n",
      " 0.00879038 0.00876535 0.00871007 0.00868936 0.00865541 0.00864605\n",
      " 0.00858069 0.00856849 0.00850857 0.00849471 0.00844331 0.00842846\n",
      " 0.00839908 0.00833786 0.00829148 0.00828018 0.00825626 0.00821621\n",
      " 0.00820164 0.00815788 0.00812044 0.00810994 0.00807566 0.00807019\n",
      " 0.00800271 0.00798978 0.00796262 0.00791545 0.00787169 0.00786071\n",
      " 0.00780401 0.00778068 0.00775679 0.00774439 0.00771555 0.00767362\n",
      " 0.00763126 0.00760058 0.00756935 0.00756382 0.00749547 0.00746603\n",
      " 0.00746109 0.0074176  0.0073765  0.00734069 0.00731542 0.00730472\n",
      " 0.00728368 0.00723041 0.00717539 0.00713308 0.00711815 0.00707253\n",
      " 0.00705599 0.00701219 0.0070026  0.00697832 0.00690017 0.0068574\n",
      " 0.00683636 0.00681598 0.00679664 0.00676127 0.00672741 0.00671542\n",
      " 0.00664824 0.00658269 0.00657092 0.00655534 0.00654875 0.0065214\n",
      " 0.00643767 0.00638773 0.0063304  0.0062766  0.00621241 0.00617061\n",
      " 0.00615018 0.00606172 0.00603001 0.00597336 0.00590202 0.00589013\n",
      " 0.00583321 0.00577905 0.0056895  0.00560917 0.0055018  0.00446371]\n"
     ]
    }
   ],
   "source": [
    "vector_space = []\n",
    "NUM_COMPONENTS= 300 #you can select any number of components.\n",
    "\n",
    "\n",
    "### Vocabulary cleaning\n",
    "for i in vocab:\n",
    "    w = vocab_clean(i)\n",
    "    vector_space.append(wv_from_bin[w])\n",
    "\n",
    "\n",
    "        \n",
    "vector_space = np.array(vector_space)\n",
    "covariance_matrix = np.cov(vector_space.T)\n",
    "values, vectors = np.linalg.eig(covariance_matrix)\n",
    "sorted_index = np.argsort(values)[::-1]\n",
    "sorted_eigenvalue = values[sorted_index]\n",
    "sorted_eigenvectors = vectors[:,sorted_index]\n",
    "eigenvector_subset = sorted_eigenvectors[:,0:NUM_COMPONENTS]\n",
    "print(sorted_eigenvalue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - Validation split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.05, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation \n",
    "#### Turns out now as good of a method to use here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_AUG = 1000\n",
    "\n",
    "import random\n",
    "X_train_ = X_train*1\n",
    "y_train_ = y_train*1\n",
    "for _ in range(NUM_OF_AUG):\n",
    "    index1 = random.randint(0, len(X_train)-1)\n",
    "    index2 = random.randint(0, len(X_train)-1)\n",
    "    index3 = random.randint(0,len(X_train[index1])-1)\n",
    "    index4 = random.randint(0,len(X_train[index1])-1)\n",
    "    index5 = random.randint(0,len(X_train[index2])-1)\n",
    "    index6 = random.randint(0,len(X_train[index2])-1)\n",
    "    \n",
    "    splice1 = X_train[index1][min(index3,index4): max(index3,index4)]\n",
    "    splice2  = X_train[index2][min(index5,index6): max(index5,index6)]\n",
    "    X_train_.append(splice1+ splice2)\n",
    "    splice1 = y_train[index1][min(index3,index4):max(index3,index4)]\n",
    "    splice2  = y_train[index2][min(index5,index6): max(index5,index6)]\n",
    "    y_train_.append(splice1+ splice2) \n",
    "\n",
    "X_train = X_train_\n",
    "y_train = y_train_                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4750, 42, 300)\n",
      "(250, 42, 300)\n"
     ]
    }
   ],
   "source": [
    "## Vectorizing the data. \n",
    "\n",
    "x_train_vectorized = np.zeros((len(X_train),MAX_LEN,NUM_COMPONENTS))\n",
    "x_original_length_train = []\n",
    "for sentence_ind in range(len(X_train)):\n",
    "    x_original_length_train.append(len(X_train[sentence_ind]))\n",
    "    for word_ind in range(len(X_train[sentence_ind])):\n",
    "        i = X_train[sentence_ind][word_ind]\n",
    "        vector = wv_from_bin[vocab_clean(i)]\n",
    "        # vector = vector @ eigenvector_subset\n",
    "        \n",
    "        x_train_vectorized[sentence_ind, word_ind] = vector\n",
    "\n",
    "x_test_vectorized = np.zeros((len(X_test),MAX_LEN,NUM_COMPONENTS))\n",
    "x_original_length_test = []\n",
    "for sentence_ind in range(len(X_test)):\n",
    "    x_original_length_test.append(len(X_test[sentence_ind]))\n",
    "    for word_ind in range(len(X_test[sentence_ind])):\n",
    "        i = X_test[sentence_ind][word_ind]\n",
    "        vector = wv_from_bin[vocab_clean(i)]\n",
    "        # vector = vector \n",
    "        \n",
    "        x_test_vectorized[sentence_ind, word_ind] = vector\n",
    "x_original_length_train = np.array(x_original_length_train)\n",
    "x_original_length_test = np.array(x_original_length_test)\n",
    "print(x_train_vectorized.shape)\n",
    "print(x_test_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.0\n",
      "(4750, 42)\n",
      "(250, 42)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_digit_train  = np.zeros((len(X_train),MAX_LEN))\n",
    "for sentence_ind in range(len(y_train)):\n",
    "    for tag_ind in range(len(y_train[sentence_ind])):\n",
    "        y_digit_train[sentence_ind,tag_ind] = target_name_to_index[y_train[sentence_ind][tag_ind]]\n",
    "print(len(target_name_to_index)/2)\n",
    "print(y_digit_train.shape)\n",
    "\n",
    "y_digit_test  = np.zeros((len(X_test),MAX_LEN))\n",
    "for sentence_ind in range(len(y_test)):\n",
    "    for tag_ind in range(len(y_test[sentence_ind])):\n",
    "        y_digit_test[sentence_ind,tag_ind] = target_name_to_index[y_test[sentence_ind][tag_ind]]\n",
    "print(y_digit_test.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "for i in range(len(x_train_vectorized)):\n",
    "    train_dataset.append((x_train_vectorized[i],\n",
    "                          y_digit_train[i],\n",
    "                          x_original_length_train[i]))\n",
    "    \n",
    "test_dataset = []\n",
    "for i in range(len(x_test_vectorized)):\n",
    "    test_dataset.append((x_test_vectorized[i],\n",
    "                          y_digit_test[i],\n",
    "                          x_original_length_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_size, batch_size=64):\n",
    "        '''\n",
    "        hidden_dim: can be anything, usually 32 or 64.\n",
    "        vocab_size: vocabulary size includes an index for padding.\n",
    "        output_size: We need to exclude the index for padding here.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # In this case, vocab_size is 9, embedding_dim is 6.\n",
    "\n",
    "        # Prepare our model for minibatch based training.\n",
    "        self.batch_size = batch_size\n",
    "        self.ini_1 = nn.Linear(embedding_dim, 2048)\n",
    "        self.ini_2 = nn.Linear(2048, 2048)\n",
    "        self.ln = nn.LayerNorm(2048)\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        # output_size = tagset_size - 1 to discount padding tag.\n",
    "        self.fc1= nn.Linear(hidden_dim*2, output_size)\n",
    "        self.fc2 = nn.Linear(256, output_size)\n",
    "        self.l_relu =  nn.LeakyReLU(0.02)\n",
    "\n",
    "        # Note: the commented line below is what we will do to train our initial hidden state.\n",
    "        \n",
    "        self.lstm = nn.RNN(2048,hidden_dim,2,\n",
    "                            dropout = 0.2,\n",
    "                            batch_first = True,\n",
    "                            bidirectional=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    def forward(self, sentences, X_lengths):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentences: padded sentences tensor. Each element of the tensor is an array of words.\n",
    "        X_lengths: length of sentence tensor. Each element of the tensor is the original\n",
    "                   length of the unpadded sentence.\n",
    "        Returns\n",
    "        -------\n",
    "        '''\n",
    "        # Dimensions of tensors:\n",
    "        # (Note that seq_len is max length)\n",
    "        # Shape of embedding (embeds): batch_size, seq_len, hidden_dim\n",
    "        # Shape of embedding post packing (embeds): batch_size, orig_len, hidden_dim\n",
    "        # Shape of self.hidden: (num_layers*num_directions, batch_size, hidden_dim)\n",
    "        # Shape of lstm_out: batch_size, seq_len, hidden_dim\n",
    "        # Shape of tag_scores: batch_size, 1\n",
    "        \n",
    "        batch_size, seq_len,dimension = sentences.size()\n",
    "        embeds = sentences\n",
    "        embeds = self.ini_1(embeds)\n",
    "        # embeds = self.dropout(embeds)\n",
    "        embeds = self.ln(embeds)\n",
    "        embeds = self.l_relu(embeds)\n",
    "        \n",
    "        # embeds = self.ini_2(embeds)\n",
    "        # embeds = self.ln(embeds)\n",
    "        # embeds = self.l_relu(embeds)\n",
    "        \n",
    "        # embeds = self.ini_3(embeds)\n",
    "        # embeds = self.l_relu(embeds)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "\n",
    "        out = self.fc1(lstm_out)\n",
    "        # out = self.ln2(out)\n",
    "        # out = self.l_relu(out)\n",
    "        # out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX LENTH: 42\n",
      "NUMBER OF PRINCEPLE COMPONENT: 300\n",
      "NUMBER OF CATAGORIES: 33\n"
     ]
    }
   ],
   "source": [
    "BATCHSIZE = 2048\n",
    "print(\"MAX LENTH:\",MAX_LEN)\n",
    "print(\"NUMBER OF PRINCEPLE COMPONENT:\",NUM_COMPONENTS)\n",
    "print(\"NUMBER OF CATAGORIES:\",CAT_NUM)\n",
    "device = torch.device(\"cuda\")\n",
    "network = LSTMTagger(embedding_dim = NUM_COMPONENTS,\n",
    "                     hidden_dim  = 256,\n",
    "                     output_size = CAT_NUM,\n",
    "                     batch_size = BATCHSIZE)\n",
    "model = network.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0022,weight_decay=1e-5)\n",
    "scheduler = StepLR(optimizer, step_size=4, gamma=0.885)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=BATCHSIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=BATCHSIZE)\n",
    "loss_fn =  nn.CrossEntropyLoss( reduction='sum')\n",
    "def train(model, device, train_loader, optimizer, epoch, loss_fn,batch_size, log_interval=45):\n",
    "    model.train()\n",
    "    lose = 0 \n",
    "    for batch_idx, (data, target,length) in enumerate(train_loader):\n",
    "        batch_size = data.size()[0]\n",
    "        data, target = data.to(device).type(torch.cuda.FloatTensor), target.to(device).type(torch.cuda.LongTensor)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model.forward(data, length)\n",
    "        \n",
    "        loss =  loss_fn(y_pred.view(batch_size * MAX_LEN, -1),\n",
    "                        target.view(batch_size * MAX_LEN) )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lose += loss.item()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch+1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return lose/len(train_loader.dataset)\n",
    "def test(model, device, test_loader, batch_size):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target, length  in test_loader:\n",
    "            batch_size = data.size()[0]\n",
    "            data, target = data.to(device).type(torch.cuda.FloatTensor), target.type(torch.cuda.LongTensor)\n",
    "            y_pred = model.forward(data, length)\n",
    "            test_loss = loss_fn(y_pred.view(batch_size * MAX_LEN, -1),\n",
    "                        target.view(batch_size * MAX_LEN) )\n",
    "            loss += test_loss.item()\n",
    "\n",
    "    loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}\\n'.format(\n",
    "        loss))\n",
    "    return loss\n",
    "    \n",
    "    \n",
    "### Training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.75 GiB (GPU 0; 8.00 GiB total capacity; 4.43 GiB already allocated; 0 bytes free; 7.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chang\\OneDrive\\Desktop\\test\\eBay_ML_Challenge_Dataset_2022\\eBay.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chang/OneDrive/Desktop/test/eBay_ML_Challenge_Dataset_2022/eBay.ipynb#ch0000020?line=1'>2</a>\u001b[0m test_e \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chang/OneDrive/Desktop/test/eBay_ML_Challenge_Dataset_2022/eBay.ipynb#ch0000020?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m150\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chang/OneDrive/Desktop/test/eBay_ML_Challenge_Dataset_2022/eBay.ipynb#ch0000020?line=4'>5</a>\u001b[0m     train_e\u001b[39m.\u001b[39mappend(train(model, device, train_loader,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chang/OneDrive/Desktop/test/eBay_ML_Challenge_Dataset_2022/eBay.ipynb#ch0000020?line=5'>6</a>\u001b[0m           optimizer, i,loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chang/OneDrive/Desktop/test/eBay_ML_Challenge_Dataset_2022/eBay.ipynb#ch0000020?line=6'>7</a>\u001b[0m           batch_size\u001b[39m=\u001b[39;49mBATCHSIZE))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chang/OneDrive/Desktop/test/eBay_ML_Challenge_Dataset_2022/eBay.ipynb#ch0000020?line=8'>9</a>\u001b[0m     test_e\u001b[39m.\u001b[39mappend(test(model, device, test_loader, batch_size\u001b[39m=\u001b[39mBATCHSIZE))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chang/OneDrive/Desktop/test/eBay_ML_Challenge_Dataset_2022/eBay.ipynb#ch0000020?line=9'>10</a>\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;32mc:\\Users\\chang\\OneDrive\\Desktop\\test\\eBay_ML_Challenge_Dataset_2022\\eBay.ipynb Cell 19'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, epoch, loss_fn, batch_size, log_interval)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chang/OneDrive/Desktop/test/eBay_ML_Challenge_Dataset_2022/eBay.ipynb#ch0000019?line=24'>25</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mforward(data, length)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chang/OneDrive/Desktop/test/eBay_ML_Challenge_Dataset_2022/eBay.ipynb#ch0000019?line=26'>27</a>\u001b[0m loss \u001b[39m=\u001b[39m  loss_fn(y_pred\u001b[39m.\u001b[39mview(batch_size \u001b[39m*\u001b[39m MAX_LEN, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chang/OneDrive/Desktop/test/eBay_ML_Challenge_Dataset_2022/eBay.ipynb#ch0000019?line=27'>28</a>\u001b[0m                 target\u001b[39m.\u001b[39mview(batch_size \u001b[39m*\u001b[39m MAX_LEN) )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chang/OneDrive/Desktop/test/eBay_ML_Challenge_Dataset_2022/eBay.ipynb#ch0000019?line=28'>29</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chang/OneDrive/Desktop/test/eBay_ML_Challenge_Dataset_2022/eBay.ipynb#ch0000019?line=29'>30</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chang/OneDrive/Desktop/test/eBay_ML_Challenge_Dataset_2022/eBay.ipynb#ch0000019?line=30'>31</a>\u001b[0m lose \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\.conda\\envs\\ebay\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/_tensor.py?line=386'>387</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/_tensor.py?line=387'>388</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/_tensor.py?line=388'>389</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/_tensor.py?line=389'>390</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/_tensor.py?line=393'>394</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/_tensor.py?line=394'>395</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/_tensor.py?line=395'>396</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\ebay\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/chang/.conda/envs/ebay/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.75 GiB (GPU 0; 8.00 GiB total capacity; 4.43 GiB already allocated; 0 bytes free; 7.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training \n",
    "train_e=[]\n",
    "test_e = []\n",
    "for i in range(150):\n",
    "      \n",
    "    train_e.append(train(model, device, train_loader,\n",
    "          optimizer, i,loss_fn=loss_fn,\n",
    "          batch_size=BATCHSIZE))\n",
    "          \n",
    "    test_e.append(test(model, device, test_loader, batch_size=BATCHSIZE))\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.940736293792725\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLX0lEQVR4nO3deXhU9d3//+fs2ScEQhZIICAKKCqLIuC31ZKKYBEVa7XUgvoDW0FFa620QlurotZ6o9Rbqnfd7qJWeysutVgKClUhbAU3BARkEZKwJZOFJJOZ8/vjzEx2SMIkJyGvx3WdaybnnDl5J4POK5/zWWyGYRiIiIiIdCB2qwsQERERqU8BRURERDocBRQRERHpcBRQREREpMNRQBEREZEORwFFREREOhwFFBEREelwFFBERESkw3FaXUBrBINB9u/fT2JiIjabzepyREREpBkMw6CkpITMzEzs9uO3kXTKgLJ//36ysrKsLkNERERaYe/evfTu3fu453TKgJKYmAiYP2BSUpLF1YiIiEhz+Hw+srKyIp/jx9MpA0r4tk5SUpICioiISCfTnO4Z6iQrIiIiHY4CioiIiHQ4CigiIiLS4XTKPigiIiJtJRAI4Pf7rS6jU3I4HDidzqhMAaKAIiIiElJaWsq+ffswDMPqUjqtuLg4MjIycLvdJ3UdBRQRERHMlpN9+/YRFxdHamqqJgJtIcMwqKqq4uDBg+zatYsBAwaccDK241FAERERAfx+P4ZhkJqaSmxsrNXldEqxsbG4XC52795NVVUVMTExrb6WOsmKiIjUopaTk3MyrSZ1rhOVq4iIiIhEkQKKiIiIdDgKKCIiIgJA3759WbBggdVlAOokKyIi0qlddNFFnHvuuVEJFuvWrSM+Pv7ki4oCBZTa9qyBz5dA2mAY9mOrqxERETlphmEQCARwOk/8kZ+amtoOFTWPbvHUVvgF5D0F296zuhIREbGYYRiUV1VbsjV3orhp06axcuVKHn/8cWw2Gzabjeeffx6bzcY//vEPhg8fjsfj4cMPP2THjh1MmjSJtLQ0EhISOO+88/jXv/5V53r1b/HYbDb+53/+hyuvvJK4uDgGDBjAW2+9Fc1fc5PUglKbMzReu7rC2jpERMRyx/wBBs+z5g/WL+4bR5z7xB/Rjz/+ONu2beOss87ivvvuA+Dzzz8H4J577uHRRx+lX79+dOvWjb179zJhwgQeeOABPB4PL774IhMnTmTr1q1kZ2c3+T1++9vf8sgjj/D73/+ehQsXMmXKFHbv3k1KSkp0ftgmqAWltnBA8SugiIhIx+f1enG73cTFxZGenk56ejoOhwOA++67j+9+97v079+flJQUzjnnHG6++WbOOussBgwYwO9+9zv69+9/whaRadOmcd1113Haaafx4IMPUlpaytq1a9v8Z1MLSm1qQRERkZBYl4Mv7htn2fc+WSNGjKjzdWlpKb/5zW/4+9//zoEDB6iurubYsWPs2bPnuNc5++yzI8/j4+NJSkqisLDwpOs7EQWU2pwe87G60to6RETEcjabrVm3WTqq+qNx7rrrLpYtW8ajjz7KaaedRmxsLFdffTVVVVXHvY7L5arztc1mIxgMRr3e+jrvb74tuEJrL1Qfs7YOERGRZnK73QQCgROe99FHHzFt2jSuvPJKwGxR+frrr9u4utZTH5Ta1IIiIiKdTN++fcnLy+Prr7/m0KFDTbZuDBgwgNdff51NmzaxefNmfvjDH7ZLS0hrKaDUpj4oIiLSydx11104HA4GDx5Mampqk31KHnvsMbp168bo0aOZOHEi48aNY9iwYe1cbfPZjOYOtu5AfD4fXq+X4uJikpKSonfhwztg4TBwJ8Iv90XvuiIi0uFVVFSwa9cucnJyiImJsbqcTut4v8eWfH6rBaU2taCIiIh0CAootYU7yQb9EDxxhyMRERFpGwootYU7yYJaUURERCykgFKbs9a9Mo3kERERsYwCSm12B9hDE9L4NReKiIiIVRRQ6lNHWREREcspoNSnydpEREQsp4BSn6a7FxERsZwCSn1qQREREbGcAkp96oMiIiKdyEUXXcTs2bOjdr1p06ZxxRVXRO16raWAUl84oPgVUERERKyigFKfWlBERKSTmDZtGitXruTxxx/HZrNhs9n4+uuv+eyzzxg/fjwJCQmkpaVx/fXXc+jQocjr/va3vzFkyBBiY2Pp3r07ubm5lJWV8Zvf/IYXXniBN998M3K9Dz74wJKfrcUBZdWqVUycOJHMzExsNhtLlixp8tyf/OQn2Gw2FixYUGf/kSNHmDJlCklJSSQnJ3PTTTdRWlra0lLahvqgiIgIgGFAVZk1WzPX8X388ccZNWoU06dP58CBAxw4cIDExES+853vMHToUNavX8/SpUspKCjgmmuuAeDAgQNcd9113HjjjWzZsoUPPviAq666CsMwuOuuu7jmmmu49NJLI9cbPXp0W/6Wm+Rs6QvKyso455xzuPHGG7nqqquaPO+NN95gzZo1ZGZmNjg2ZcoUDhw4wLJly/D7/dxwww3MmDGDl156qaXlRJ9G8YiICIC/HB5s+BnWLn65H9zxJzzN6/XidruJi4sjPT0dgPvvv5+hQ4fy4IMPRs579tlnycrKYtu2bZSWllJdXc1VV11Fnz59ABgyZEjk3NjYWCorKyPXs0qLA8r48eMZP378cc/55ptvuPXWW3nvvfe47LLL6hzbsmULS5cuZd26dYwYMQKAhQsXMmHCBB599NFGA027UguKiIh0Yps3b+b9998nISGhwbEdO3ZwySWXMHbsWIYMGcK4ceO45JJLuPrqq+nWrZsF1TatxQHlRILBINdffz0///nPOfPMMxscX716NcnJyZFwApCbm4vdbicvL48rr7yywWsqKyuprKwJDD6fL9pl13CGW1DUB0VEpEtzxZktGVZ971YqLS1l4sSJPPzwww2OZWRk4HA4WLZsGR9//DH//Oc/WbhwIb/61a/Iy8sjJyfnZKqOqqgHlIcffhin08ltt93W6PH8/Hx69uxZtwink5SUFPLz8xt9zfz58/ntb38b7VIbF25B0SgeEZGuzWZr1m0Wq7ndbgKBQOTrYcOG8X//93/07dsXp7Pxj3mbzcaYMWMYM2YM8+bNo0+fPrzxxhvceeedDa5nlaiO4tmwYQOPP/44zz//PDabLWrXnTNnDsXFxZFt7969Ubt2AxrFIyIinUjfvn3Jy8vj66+/5tChQ8ycOZMjR45w3XXXsW7dOnbs2MF7773HDTfcQCAQIC8vjwcffJD169ezZ88eXn/9dQ4ePMigQYMi1/vkk0/YunUrhw4dwu/3W/JzRTWg/Pvf/6awsJDs7GycTidOp5Pdu3fzs5/9jL59+wKQnp5OYWFhnddVV1dz5MiRJjvkeDwekpKS6mxtxqWAIiIincddd92Fw+Fg8ODBpKamUlVVxUcffUQgEOCSSy5hyJAhzJ49m+TkZOx2O0lJSaxatYoJEyZw+umnc++99/KHP/wh0r90+vTpnHHGGYwYMYLU1FQ++ugjS36uqN7iuf7668nNza2zb9y4cVx//fXccMMNAIwaNYqioiI2bNjA8OHDAVixYgXBYJCRI0dGs5zWUQuKiIh0IqeffjqrV69usP/1119v9PxBgwaxdOnSJq+XmprKP//5z6jV11otDiilpaV89dVXka937drFpk2bSElJITs7m+7du9c53+VykZ6ezhlnnAGYv5hLL72U6dOns2jRIvx+P7NmzeLaa6+1fgQPaBSPiIhIB9DiWzzr169n6NChDB06FIA777yToUOHMm/evGZfY/HixQwcOJCxY8cyYcIELrzwQp5++umWltI2wqN4/JoHRURExCotbkG56KKLMJo5wx3A119/3WBfSkpKx5iUrTFqQREREbGc1uKpT31QRERELKeAUp9G8YiIiFhOAaU+taCIiHRpLenGIA1F6/engFKf+qCIiHRJDocDgKqqKosr6dzKy8sBcxTvyYj6VPednkbxiIh0SU6nk7i4OA4ePIjL5cJu19/wLWEYBuXl5RQWFpKcnBwJfK2lgFKfWlBERLokm81GRkYGu3btYvfu3VaX02klJyc3OTN8Syig1OcKr2asFhQRka7G7XYzYMAA3eZpJZfLddItJ2EKKPWpBUVEpEuz2+3ExMRYXUaXpxts9dUexaOe3CIiIpZQQKkvHFCMIASsWWJaRESkq1NAqc9Zq1lPc6GIiIhYQgGlvnAfFFA/FBEREYsooNRns9Xqh6KRPCIiIlZQQGmMRvKIiIhYSgGlMVqPR0RExFIKKI0JBxS/AoqIiIgVFFAaoxYUERERSymgNEZ9UERERCylgNIYrccjIiJiKQWUxqgFRURExFIKKI1xhlpQ/GpBERERsYICSmMiLSjqJCsiImIFBZTGREbx6BaPiIiIFRRQGuPSVPciIiJWUkBpjFpQRERELKWA0hj1QREREbGUAkpjIqN4FFBERESsoIDSGLWgiIiIWEoBpTHqgyIiImIpBZTGaBSPiIiIpRRQGqMWFBEREUspoDQmHFA01b2IiIglFFAaoxYUERERSymgNCYSUDSKR0RExAoKKI1xKaCIiIhYqcUBZdWqVUycOJHMzExsNhtLliyJHPP7/fziF79gyJAhxMfHk5mZyY9//GP2799f5xpHjhxhypQpJCUlkZyczE033URpaelJ/zBRoxYUERERS7U4oJSVlXHOOefw5JNPNjhWXl7Oxo0bmTt3Lhs3buT1119n69atXH755XXOmzJlCp9//jnLli3jnXfeYdWqVcyYMaP1P0W0RSZqUx8UERERK9gMwzBa/WKbjTfeeIMrrriiyXPWrVvH+eefz+7du8nOzmbLli0MHjyYdevWMWLECACWLl3KhAkT2LdvH5mZmSf8vj6fD6/XS3FxMUlJSa0tv2mHvoI/DgePF+bsif71RUREuqCWfH63eR+U4uJibDYbycnJAKxevZrk5ORIOAHIzc3FbreTl5fX6DUqKyvx+Xx1tjalqe5FREQs1aYBpaKigl/84hdcd911kaSUn59Pz54965zndDpJSUkhPz+/0evMnz8fr9cb2bKystqy7Jo+KIFKaH0Dk4iIiLRSmwUUv9/PNddcg2EYPPXUUyd1rTlz5lBcXBzZ9u7dG6UqmxAexQNqRREREbGAsy0uGg4nu3fvZsWKFXXuM6Wnp1NYWFjn/Orqao4cOUJ6enqj1/N4PHg8nrYotXHOegHFFdt+31tERESi34ISDifbt2/nX//6F927d69zfNSoURQVFbFhw4bIvhUrVhAMBhk5cmS0y2kduxNsoV+NRvKIiIi0uxa3oJSWlvLVV19Fvt61axebNm0iJSWFjIwMrr76ajZu3Mg777xDIBCI9CtJSUnB7XYzaNAgLr30UqZPn86iRYvw+/3MmjWLa6+9tlkjeNqFzQbOWPCXaT0eERERC7R4mPEHH3zAxRdf3GD/1KlT+c1vfkNOTk6jr3v//fe56KKLAHOitlmzZvH2229jt9uZPHkyTzzxBAkJCc2qoc2HGQM8nAPHjsAtedBzYNt8DxERkS6kJZ/fLW5BueiiizhepmlO3klJSeGll15q6bduX65YOAZUqwVFRESkvWktnqZoNlkRERHLKKA0RevxiIiIWEYBpSnhgOJXQBEREWlvCihNUQuKiIiIZRRQmqI+KCIiIpZRQGlKePZYjeIRERFpdwooTVELioiIiGUUUJqiPigiIiKWUUBpikbxiIiIWEYBpSlqQREREbGMAkpTIn1QFFBERETamwJKUyKjeBRQRERE2psCSlM0ikdERMQyCihNcYZaUPyaB0VERKS9KaA0RS0oIiIillFAaYpG8YiIiFhGAaUpLgUUERERqyigNEUtKCIiIpZRQGmK+qCIiIhYRgGlKRrFIyIiYhkFlKaoBUVERMQyCihNUR8UERERyyigNEWjeERERCyjgNIUtaCIiIhYRgGlKeGAEqyGQLW1tYiIiHQxCihNCQcUUCuKiIhIO1NAaUqdgKKRPCIiIu1JAaUpdjs43Obzas2FIiIi0p4UUI4n0lFWLSgiIiLtSQHleCKTtakPioiISHtSQDmeyHT3CigiIiLtSQHleNSCIiIiYgkFlOPRZG0iIiKWUEA5Hk13LyIiYokWB5RVq1YxceJEMjMzsdlsLFmypM5xwzCYN28eGRkZxMbGkpuby/bt2+ucc+TIEaZMmUJSUhLJycncdNNNlJaWntQP0ibUgiIiImKJFgeUsrIyzjnnHJ588slGjz/yyCM88cQTLFq0iLy8POLj4xk3bhwVFTUf8lOmTOHzzz9n2bJlvPPOO6xatYoZM2a0/qdoK+E+KOokKyIi0q6cLX3B+PHjGT9+fKPHDMNgwYIF3HvvvUyaNAmAF198kbS0NJYsWcK1117Lli1bWLp0KevWrWPEiBEALFy4kAkTJvDoo4+SmZl5Ej9OlKkFRURExBJR7YOya9cu8vPzyc3Njezzer2MHDmS1atXA7B69WqSk5Mj4QQgNzcXu91OXl5eNMs5eZqoTURExBItbkE5nvz8fADS0tLq7E9LS4scy8/Pp2fPnnWLcDpJSUmJnFNfZWUllZU1IcHn80Wz7KZFAoqmuhcREWlPnWIUz/z58/F6vZEtKyurfb6xSy0oIiIiVohqQElPTwegoKCgzv6CgoLIsfT0dAoLC+scr66u5siRI5Fz6pszZw7FxcWRbe/evdEsu2nqgyIiImKJqAaUnJwc0tPTWb58eWSfz+cjLy+PUaNGATBq1CiKiorYsGFD5JwVK1YQDAYZOXJko9f1eDwkJSXV2dpFOKBoFI+IiEi7anEflNLSUr766qvI17t27WLTpk2kpKSQnZ3N7Nmzuf/++xkwYAA5OTnMnTuXzMxMrrjiCgAGDRrEpZdeyvTp01m0aBF+v59Zs2Zx7bXXdqwRPKAWFBEREYu0OKCsX7+eiy++OPL1nXfeCcDUqVN5/vnnufvuuykrK2PGjBkUFRVx4YUXsnTpUmJiYiKvWbx4MbNmzWLs2LHY7XYmT57ME088EYUfJ8oia/GoD4qIiEh7shmGYVhdREv5fD68Xi/FxcVte7tn7TPw7l0weBJc82LbfR8REZEuoCWf351iFI9l1IIiIiJiCQWU41EfFBEREUtEdaK2zm7XoTI27T1KWmIMo0/roVE8IiIiFlELSi0fbj/IHX/dzIurd5s71IIiIiJiCQWUWuI9ZoNSWVW1uSPSB0UBRUREpD0poNQSDiillaGA4oo1HxVQRERE2pUCSi0JoYBSXhkwd2gUj4iIiCUUUGpp0IIS6SSr1YxFRETakwJKLQkeB1C7D4pWMxYREbGCAkotkU6y9VtQqiug8024KyIi0mkpoNQSDij+gEFldQBc4fWDDAhUWVeYiIhIF6OAUku8u2beurLKQE0LCmgkj4iISDtSQKnFYbcR6wr1Q6msBocbsJkH1Q9FRESk3Sig1FNnJI/NppE8IiIiFlBAqSfeU6sFBTQXioiIiAUUUOoJ90NpMBdKtVpQRERE2osCSj0JkaHGodlkXZoLRUREpL0poNTT8BaPVjQWERFpbwoo9TS5orFfAUVERKS9KKDUk9BgNtkmVjQuKdBtHxERkTaigFJPzTDj46xovP8/sGAIvD6jnasTERHpGhRQ6ml6PZ5ao3g+XgiBSjOoiIiISNQpoNSTUL+TbP1RPL4D8MWb5vNjR9u5OhERka5BAaWeOjPJQsNRPBueg2DoWKUPAv52rlBEROTUp4BST3iitppRPOGp7ivMVpT1z9V9QUVxO1YnIiLSNSig1NOwk2ytFpTPl0BZISRmgDvR3K/bPCIiIlGngFJP02vxVMDaP5nPR9wEcSnmcwUUERGRqFNAqafBPCiu0Dwouz+CbzaAww3Dp0FsN3O/AoqIiEjUKaDU07CTbKgFJTyk+MyrICG1pgWl/Eg7VygiInLqU0CpJ9yCUl4VwDCMmj4oYSNDk7OpBUVERKTNKKDUE25BCQQNKquDdQNK7/Og13DzuQKKiIhIm1FAqSfO5Yg8L62srhtQzr+55rkCioiISJtRQKnHbrcR7641kseTYB5ISIPBk2pOVEARERFpM06rC+iI4j1OyqoCZgvKgEtg2FQ480pwumtOUkARERFpMwoojUjwOCksqaSsMmAOM778iYYnxYbnQdEoHhERkWiL+i2eQCDA3LlzycnJITY2lv79+/O73/3OHBETYhgG8+bNIyMjg9jYWHJzc9m+fXu0S2m1uPqTtTVGLSgiIiJtJuoB5eGHH+app57ij3/8I1u2bOHhhx/mkUceYeHChZFzHnnkEZ544gkWLVpEXl4e8fHxjBs3joqKimiX0yrh9XhKFVBEREQsEfVbPB9//DGTJk3isssuA6Bv3768/PLLrF27FjBbTxYsWMC9997LpElmp9MXX3yRtLQ0lixZwrXXXhvtklqswWyyjQkHlIpiCAbA7mj6XBEREWmRqLegjB49muXLl7Nt2zYANm/ezIcffsj48eMB2LVrF/n5+eTm5kZe4/V6GTlyJKtXr270mpWVlfh8vjpbW2owm2xjYpNrnmtFYxERkaiKegvKPffcg8/nY+DAgTgcDgKBAA888ABTpkwBID8/H4C0tLQ6r0tLS4scq2/+/Pn89re/jXapTYqPtKAEmj7J4TJXNK4qMW/zhKe+FxERkZMW9RaUV199lcWLF/PSSy+xceNGXnjhBR599FFeeOGFVl9zzpw5FBcXR7a9e/dGseKGEkKdZMurjtOCAhAXus2j9XhERESiKuotKD//+c+55557In1JhgwZwu7du5k/fz5Tp04lPT0dgIKCAjIyMiKvKygo4Nxzz230mh6PB4/HE+1Sm9SsWzxg9kMp2qOOsiIiIlEW9RaU8vJy7Pa6l3U4HASDQQBycnJIT09n+fLlkeM+n4+8vDxGjRoV7XJapVmdZEEjeURERNpI1FtQJk6cyAMPPEB2djZnnnkm//nPf3jssce48cYbAbDZbMyePZv777+fAQMGkJOTw9y5c8nMzOSKK66IdjmtUtOCcpw+KKCAIiIi0kaiHlAWLlzI3LlzueWWWygsLCQzM5Obb76ZefPmRc65++67KSsrY8aMGRQVFXHhhReydOlSYmJijnPl9hOvFhQRERFLRT2gJCYmsmDBAhYsWNDkOTabjfvuu4/77rsv2t8+KiKLBZ6ok6wCioiISJvQasaNaH4nWa3HIyIi0hYUUBqhTrIiIiLWUkBpRLMmagMFFBERkTaigNKIeE9NH5TaqzA3oIAiIiLSJhRQGhG+xWMYUF51nFYUBRQREZE2oYDSiFiXA7vNfH7cfijh9XeOFUFoIjoRERE5eQoojbDZbMS7Q/1QjteCEpMcemJARVFblyUiItJlKKA0oVmTtTnd4E4wn+s2j4iISNQooDQh3FG2WQsGgnmbR0RERKJCAaUJzZ8LJdl8VAuKiIhI1CigNCHO3dzZZDWSR0REJNoUUJrQ/MnawiN5FFBERESiRQGlCQnhydqa3YKi9XhERESiRQGlCc1fMFC3eERERKJNAaUJWjBQRETEOgooTYj0QalSQBEREWlvCihNqLnFoxWNRURE2psCShPCnWTLT3SLJ06jeERERKJNAaUJLe4kW65RPCIiItGigNKEFvdBqSjSisYiIiJRooDShMhqxifqgxJe0dgIQqWvbYsSERHpIhRQmtDsxQJdMeCKM5+rH4qIiEhUKKA0odnzoIBG8oiIiESZAkoTwn1QyqsCBIPG8U/WejwiIiJRpYDShHALCjSno2yy+aiAIiIiEhUKKE3wOO047DagOSsa6xaPiIhINCmgNMFmsxHvbmZHWQUUERGRqFJAOQ4tGCgiImINBZTjaPZkbZruXkREJKoUUI4jElDUB0VERKRdKaAcR4tv8Wg9HhERkahQQDmOOHWSFRERsYQCynGok6yIiIg1FFCOI741AcU4wayzIiIickIKKMcRDiilze0kawSgsqSNqxIRETn1tUlA+eabb/jRj35E9+7diY2NZciQIaxfvz5y3DAM5s2bR0ZGBrGxseTm5rJ9+/a2KOWkJIRWND5hC4orFpyx5nPd5hERETlpUQ8oR48eZcyYMbhcLv7xj3/wxRdf8Ic//IFu3bpFznnkkUd44oknWLRoEXl5ecTHxzNu3DgqKiqiXc5JibSgnGgeFKh1m0cjeURERE6W88SntMzDDz9MVlYWzz33XGRfTk5O5LlhGCxYsIB7772XSZMmAfDiiy+SlpbGkiVLuPbaa6NdUqs1uw8KmAGlZL9aUERERKIg6i0ob731FiNGjOD73/8+PXv2ZOjQoTzzzDOR47t27SI/P5/c3NzIPq/Xy8iRI1m9enWj16ysrMTn89XZ2kOzR/GARvKIiIhEUdQDys6dO3nqqacYMGAA7733Hj/96U+57bbbeOGFFwDIz88HIC0trc7r0tLSIsfqmz9/Pl6vN7JlZWVFu+xGNXsmWYDYZPNRAUVEROSkRT2gBINBhg0bxoMPPsjQoUOZMWMG06dPZ9GiRa2+5pw5cyguLo5se/fujWLFTYt0km1OHxStxyMiIhI1UQ8oGRkZDB48uM6+QYMGsWfPHgDS09MBKCgoqHNOQUFB5Fh9Ho+HpKSkOlt7iHO35hZPUdsVJCIi0kVEPaCMGTOGrVu31tm3bds2+vTpA5gdZtPT01m+fHnkuM/nIy8vj1GjRkW7nJOSEJkHpQUBRevxiIiInLSoj+K54447GD16NA8++CDXXHMNa9eu5emnn+bpp58GwGazMXv2bO6//34GDBhATk4Oc+fOJTMzkyuuuCLa5ZyUcB+UCn+Q6kAQp+M4eU6dZEVERKIm6gHlvPPO44033mDOnDncd9995OTksGDBAqZMmRI55+6776asrIwZM2ZQVFTEhRdeyNKlS4mJiYl2OSclPtQHBaCsKoA3VgFFRESkPdgMo/MtHuPz+fB6vRQXF7d5f5QBv3oXf8Dg43u+Q2ZybNMn7loFL0yE2BQY9yCccWlNaBEREZEWfX5HvQXlVBPvcVJU7j9xR9nup4Hdac4ku+Qn5vN+F8Ggy2HwpJphyCIiInJCWizwBOLdzewom5QJt6yBb/8CUgdBsBq++he8fRv89yg4srMdqhURETk1KKCcQEJLJmvrMQAu/iXMXAOz1sN35kJytjkF/guToHhfG1crIiJyalBAOYFwR9lmDTWurccA+NZdcNMySOkHxXvghcuhpODErxUREeniFFBOoEULBjYmMR1+/BZ4s+HIDnhxEpQdjmKFIiIipx51kj2B8C2e8uZMd9+U5CyY+iY8NwEOboH/vQKufwMqis2+KUd2mY8VRRAMgBEAI2g+Tx1otsQ4PVH5eURERDoDBZQTiIt0km1GH5TjSelntqQ8Nx7yP4Hf92/e67a8Bd9sgB/8BdxxJ1eDiIhIJ6GAcgKRBQNbe4unttTT4cdLzL4ox46AM9YMLik50K0vJPQEmwNsdrA7wH8MVj4MO5bD4u/DD18BT+LJ1yEiItLBKaCcQHxL1uNpjvQhcPtm8JdDQhrYbMc/P2ukGU52fwj/eyVM+ZvmVBERkVOeOsmewEl3km1MTJLZefZE4QSgzyiz/0pMMuxbZ85Wq062IiJyilNAOYHIPCgn00n2ZPUaDtP+DvGpZv+VZ8fB9mXQ+VYpEBERaRYFlBOoucVzkp1kT1b6WTDtXUjMhMPbYfHV8Mx3YOtSBRURETnlKKCcQPd4NwCFvgqLK8HsZHvzKhg1y+xgu38jvPwDePoi2Pae1dWJiIhEjQLKCeT0iAfg68NlBIMdoKUiIRXGPQCzP4XRt4ErDg5sgpeugU0vWV2diIhIVCignEDvbrG4HDYq/EH2Fx+zupwaCalwye/MoDJsqrnvnTuh4Atr6xIREYkCBZQTcDrs9OlutqLsOFhmcTWNiO8B31sA/cdC9TF4bSpUllpdlYiIyElRQGmG/qlmQNl5sIN+8NvtcNXTZgfaQ9vgndnqOCsiIp2aAkoz9EtNAGBnR2xBCYvvAVc/a85E++lrsOF5qysSERFpNQWUZugX6ii781AHbUEJ6zMKcn9tPv/HL+DAZmvrERERaSUFlGbo39NsQdlR2IFbUMJG3Qqnj4dAJbw6FY4VWV2RiIhIiymgNEP/HmZAyfdVRHfK+7Zgt8MV/w3ebDi6C169HqqrrK5KRESkRRRQmsEb54pM2LbrUCdoRYlLgWsXgzsBdq2Ct29Tp1kREelUFFCaqV9qeKhxB++HEpZxNnz/ebPT7OaX4YOHrK5IRESk2RRQmql/aCRPh5wLpSkDvguX/cF8vvIh+M9ia+sRERFpJgWUZurX0edCacqIG+DCO8znb98GO963th4REZFmUEBppn49OsFcKE35zjw4azIEq+HVH8P2ZVZXJCIiclwKKM0UaUE5VNoxFg1sCbsdrngK+oyBSh8svhr+bzqUHbK6MhERkUYpoDRTVkpcZNHAA74Kq8tpOacHprwGo2aBzQ6fvgp/PA82v6IRPiIi0uEooDSTy2EnOyUO6IT9UMLc8TDuAfj//gVpZ8GxI/DGzfCXq8B3wOrqREREIhRQWiC8Js+Owk4aUMJ6DYcZH8DYeeDwwI4V8D+5ULjF6spEREQABZQWCQ813tkZJms7EYcL/t/P4KcfQffTwLcP/jzOnNhNRETEYgooLVAz1PgUCChhPQbATcsgexRUFsP/XgWfvGp1VSIi0sUpoLRA/846F8qJxKXA9UvgzCsh6IfXp8OqR9V5VkRELKOA0gLhuVD2F1dQXtXBFw1sKVcMTH4WRt9qfr3id/D27RA4xX5OERHpFBRQWqBbvJuU0KKBp9RtnjC7HS65H8b/3hyKvPEFePkHUFlidWUiItLFtHlAeeihh7DZbMyePTuyr6KigpkzZ9K9e3cSEhKYPHkyBQUFbV1KVPTrEZ6w7RQMKGEjZ8APFoMrDr76Fzw7Hnz7ra5KRES6kDYNKOvWreNPf/oTZ599dp39d9xxB2+//TavvfYaK1euZP/+/Vx11VVtWUrURFY17uxDjU9k4ASY9neI7wkFn8IzYyH/M6urEhGRLqLNAkppaSlTpkzhmWeeoVu3bpH9xcXF/PnPf+axxx7jO9/5DsOHD+e5557j448/Zs2aNW1VTtT0O5WGGp9Ir2HmpG49zoCS/fDspWaLioiISBtrs4Ayc+ZMLrvsMnJzc+vs37BhA36/v87+gQMHkp2dzerVqxu9VmVlJT6fr85mlchcKKfaSJ6mdOsDN70Hff8fVJXA4mtg7TNWVyUiIqe4Ngkor7zyChs3bmT+/PkNjuXn5+N2u0lOTq6zPy0tjfz8/EavN3/+fLxeb2TLyspqi7KbpfZcKJ1u0cDWiu0GP3odzp0CRgDevQvevVsjfEREpM1EPaDs3buX22+/ncWLFxMTExOVa86ZM4fi4uLItnfv3qhctzWyU+Jw2m0c8wfI74yLBraW0w2TnoSxvza/XvsnePlaqLCuNUtERE5dUQ8oGzZsoLCwkGHDhuF0OnE6naxcuZInnngCp9NJWloaVVVVFBUV1XldQUEB6enpjV7T4/GQlJRUZ7NK3UUDu0A/lNpsNvh/d8I1L4IzFr5aBs+Og6I9VlcmIiKnmKgHlLFjx/Lpp5+yadOmyDZixAimTJkSee5yuVi+fHnkNVu3bmXPnj2MGjUq2uW0iZqOsl2kH0p9gyfBDX+HhDQo/AKevhj2dPwOziIi0nk4o33BxMREzjrrrDr74uPj6d69e2T/TTfdxJ133klKSgpJSUnceuutjBo1igsuuCDa5bSJ/qnx/GtLFxhqfDy9hsP0FeZtnvxP4fnvwff+C4Zdb3VlIiJyCrBkJtn/+q//4nvf+x6TJ0/mW9/6Funp6bz++utWlNIqkblQutotnvq8veHG92DQ5eYaPm/NgqW/VOdZERE5aTbD6Hwrwvl8PrxeL8XFxZb0R/l0XzET//ghcW4HG+d+lxiXo91r6FCCQVj5MKx8yPy6/1i4+lmITba0LBER6Vha8vmttXha4axeSfRKjqW8KsD7XxZaXY717Ha4eA58/3mz8+yO5fDceChpfNi4iIjIiSigtILNZuOyszMAeOfTAxZX04GceaU5qVtCutl59tlxcPRrq6sSEZFOSAGllb4XCigrthRSXqU+FxEZ58CNSyG5jxlOnr0UCr+0uioREelkFFBaaUgvL9kpcRzzB1ih2zx1peSYnWdTB0HJAfN2zzcbra5KREQ6EQWUVqpzm2ezbvM0kJQBN7xrDkc+dgReuBx2/dvqqkREpJNQQDkJ4ds8728tpLRSt3kaiEuBH79Zs9DgXybDl+9aXZWIiHQCCignYXBGEjk94qmsDrJ8S4HV5XRMnkSY8jc44zIIVMJffwSbX7G6KhER6eAUUE6CzWaLtKK884lu8zTJFWOu33POD83VkN+4GdYssroqERHpwBRQTlK4H8rKrQfxVfgtrqYDczjN1ZAvuMX8eukv4P350PnmCRQRkXaggHKSzkhL5LSeCVQFgvzrC93mOS67HcY9CBffa3698iF471cKKSIi0oACyknSbZ4Wstng2z+HCY8CNljzJPz7UaurEhGRDkYBJQrCAeXf2w9SXK7bPM1y/nQY/7D5fMX9sPFFa+sREZEORQElCk7rmcjA9ET8AYP3vtD6M8028ma48A7z+du3w9Z/WFuPiIh0GAooUXLZEN3maZWxv4Zzp4ARhNemwZ48qysSEZEOQAElSiaekwnAh9sP8k3RMYur6URsNpj4OAy4BKor4KVrtHaPiIgooERL3x7xjO7fnaABL+ftsbqczsXhgu8/D71GQEUR/O+VcHiH1VWJiIiFFFCi6PoL+gDwyro9VFUHLa6mk3HHw5TXIHUglOyH5y9TSBER6cIUUKIod3AaPRM9HCqt4r3P1Vm2xeJSYOrboZByAJ6bAIe+sroqERGxgAJKFLkcdq49PxuAv6zZbXE1nVRCT5j6DqQOgtJ8syXl0HarqxIRkXamgBJl152fhcNuI2/XEbYVlFhdTueUkGq2pPQcXBNSDm6zuioREWlHCihRluGNJXdQTwAWqxWl9SIh5UwoLYDnLoWdH1hdlYiItBMFlDbwo1Bn2dc3fkNZZbXF1XRi8T3MkJJxDpQfNkf3/PsPEFQHZBGRU50CShsY078HfbvHUVJZzZub9ltdTucW3x1ufA/O/ZE5mdvy++CvU+BYkdWViYhIG1JAaQN2u40pI81WlL+s2Y2h1XpPjisWJv3RnNDN4Yat78LTF0H+p1ZXJiIibUQBpY1cPbw3bqedLw74+M/eIqvL6fxsNhg+zWxN8WbD0V3w9MXwz7lQ4bO6OhERiTIFlDbSLd7NxLPN6e//slqdZaOm1zC4eSWcPh6Cfvj4CfjjCPjPYvVNERE5hSigtKEfXWDOifLW5v18sV9/5UdNXApc9zJc91dI6WeO8nnzFvhzLuxdZ3V1IiISBQoobWhodjcuPTOd6qDBz/+2GX9Af+FHjc0GZ1wKt6yB3N+COwG+2WCGlL9cDXvXWl2hiIicBAWUNnbfFWfijXXx+X4fT6/aaXU5px6nBy6cDbduNEf62Bzw1TL483fhxUnw9UdWVygiIq2ggNLGeibGMO97gwF4fPl2viostbiiU1RiGlzxJMxaB0N/BHanObHb8xPguctg98dWVygiIi2ggNIOrhrWi2+fnkpVdZC7/7aZQFDDjttM9/4w6UmzRWX4DWB3we4P4bnx8L9XwTcbra5QRESaQQGlHdhsNh68aggJHicb9xTxwsdfW13Sqa9bH5i4AG7fFAoqTtixHJ65GF6ZAgVfWF2hiIgchwJKO+mVHMs94wcC8Pv3trLncLnFFXUR3t5mUJm1Ds6+FrDBl+/AU6PhrVuhpMDqCkVEpBEKKO3oh+dnMzInhWP+AD//22aqqjWqp92k9IOr/mSO+hl0OWDAxhfhiaGw6vfgP2Z1hSIiUosCSjuy2208PPlsYl0O8nYd4daXN2rocXvrORB+8L9w0zLoNQL8ZbDiflg4Ajb/FYIBqysUERHaIKDMnz+f8847j8TERHr27MkVV1zB1q1b65xTUVHBzJkz6d69OwkJCUyePJmCgq7R1N63RzyLrh+O22Hnvc8LmP3XTVQrpLS/rPPh//sXTP4zeLPAtw/emAFPjoRNL0PAb3WFIiJdWtQDysqVK5k5cyZr1qxh2bJl+P1+LrnkEsrKyiLn3HHHHbz99tu89tprrFy5kv3793PVVVdFu5QO69unp7Lo+mG4HDb+/skBfvaaRvZYwmaDIVeb/VPGzoOYZDi8HZb8BBYOg/XPQnWl1VWKiHRJNqONl9o9ePAgPXv2ZOXKlXzrW9+iuLiY1NRUXnrpJa6++moAvvzySwYNGsTq1au54IILTnhNn8+H1+uluLiYpKSktiy/Tf3z83xuWbyR6qDB5GG9+f3VZ2O326wuq+uq8MH6P8PqJ6HsoLkvMQMu+Km5UGGM19LyREQ6u5Z8frd5H5Ti4mIAUlJSANiwYQN+v5/c3NzIOQMHDiQ7O5vVq1c3eo3Kykp8Pl+d7VRwyZnpLLxuKA67jf/buI+f/+0TyquqrS6r64pJggvvgNs/gUsfhsRMKDkAy+bBY2fCP++F4m+srlJEpEto04ASDAaZPXs2Y8aM4ayzzgIgPz8ft9tNcnJynXPT0tLIz89v9Drz58/H6/VGtqysrLYsu12NH5LBf/3gXOw2+L+N+/juY6tY8WXX6I/TYbnj4IKfmHOoXP5H6HEGVJXAxwvh8bPh9Zth33po28ZHEZEurU0DysyZM/nss8945ZVXTuo6c+bMobi4OLLt3bs3ShV2DJefk8mz086jV3Is3xQd48bn13PL4g0U+CqsLq1rc3pg2PXm0OQfvgp9LoRgNXzyCvzPWHhqDOT9CY4dtbpSEZFTTpsFlFmzZvHOO+/w/vvv07t378j+9PR0qqqqKCoqqnN+QUEB6enpjV7L4/GQlJRUZzvVXHRGT5bd+S1mfKsfDruNdz/NZ+wfVvLcR7s0ysdqdjucPg5u+DtMX2FO+OaMgcLP4R93wx8GwuszYNe/1aoiIhIlUe8kaxgGt956K2+88QYffPABAwYMqHM83En25ZdfZvLkyQBs3bqVgQMHdrlOsk35Yr+PX77xKZv2FgEwoGcCc783mG+dnmptYVLj2FH45DXY+AIUfFazv1uOuVjhuT+EpEzr6hMR6YBa8vkd9YByyy238NJLL/Hmm29yxhlnRPZ7vV5iY2MB+OlPf8q7777L888/T1JSErfeeisAH3/cvBVnT/WAAhAMGry8bg+PvreVo+XmnBxjB/bkl5cNon9qgsXVSYRhmAsQbnwBPnvd7KsCYLPDabkweBIMuAQSelpbp4hIB2BpQLHZGh8m+9xzzzFt2jTAnKjtZz/7GS+//DKVlZWMGzeO//7v/27yFk99XSGghBWX+3lixXZe+PhrqoMGTruN60f14ZaLTiM10WN1eVJbVRl88Sb85y+w+6O6xzKHmbeJBlwCGeeat41ERLoYSwNKe+hKASVsx8FSHvj7FlZ8WQhAjMvOD8/vw83f7kdaUozF1UkDh3fAJ6/C9vdg/3/qHkvMhIGXwaDvQZ8x4HBZU6OISDtTQDmFrdp2kMeWbYv0T3E77Vx3XhY/uag/Gd5Ya4uTxpXkw/ZlZljZ8T5UldYci0mGM8bDoInQ/zvg0nsoIqcuBZRTnGEYfPjVIR7/13bW7zaHuLocNiad24sZ3+rH6WmJFlcoTfJXwK6VsOVt2PoulB+uOeaKh9MvMVdbHnAJeNTXSEROLQooXYRhGKzeeZgnlm9nzc4jkf0Xn5HKjG/154J+KU32CZIOIBiAPWvMsLLlbXPBwjBnDPQZHdrGmH1YXLqVJyKdmwJKF/SfPUd5etVOln6eH5mK4+zeXqaMzOZ7Z2cS73FaW6AcX3g00JY34Yu34OiuuscdHug9ArJHmVvWeVobSEQ6HQWULuzrQ2X8z4c7eW39PiqrzQneEjxOJp6TyXXnZzGkl1etKh2dYUDhF/D1R+ZooN0fQ1lhvZNskHYmZF9gBpa+F0Ji80bBiYhYRQFFOFxayavr9/HXdXv4+nB5ZP/gjCQmnZvJhCEZZKXEWVihNJthmKOCdn9k3hLauwaO7Gx4Xkp/6DvGnJI/+wJIzgaFURHpQBRQJCLcT+Wv6/byj8/yqaqumTb/nKxkvjckgwlnZ9ArWaNHOpWSAjOo7FljBpf8T8GotyRCXHez70rmUOg1DHqNgATNRiwi1lFAkUYdLavi758e4N1PD7Bm52GCtd75gemJfPuMVL59eioj+qTgdmoisU7lWFEorHxo3hrK/xSC/obnpQ2B/hdBv4vNDrga1iwi7UgBRU7oYEklSz/P5++f7Cdv15E6a9zFuR2M7t+d0f17cEG/7gxMT8Ru162CTsVfAQWfw/6N5kRx32yEg1vqnuPwQNb50Gt4zebtZU29ItIlKKBIixwtq+LfXx1i5daDrNx2kEOllXWOe2NdjMxJYWS/7pzXtxuDMpJwOdTC0umUHjTnYNnxPux8H3zfNDwnMcMMKr1HQO/zzdtDbvVVEpHoUECRVgsGDbbk+1i17RB5uw6zbtcRyqoCdc6Jcdk5p3cyw/p0Y3h2N87JSta6QJ2NYcCh7WY/lm82wL4N5sgho+57jc0B6WeZYSUcXFL6ay0hEWkVBRSJmupAkM/2+1iz8zBrdh7mP3uKKD7WsG9DhjeGIb28nN3by1m9vAzp5aV7gkJLp1JVBgc+gX3raraSAw3Pi/HWdL7tcTr0GADdT4PY5HYvWUQ6FwUUaTPBoMHOQ6Vs3F3Eht1H2bjnKF8dLKWxf0UZ3hjOzEzizEwvZ2YmMTgziV7JsZqHpbMwDCjeB/vWwr71Zj+WA5uguqLx8+N6mIElfQhknGNuqWdoMUQRiVBAkXZVVlnN5/t9fLKviE+/KeaTfcXsOlTW6LmJMU4GpScxKCORgRlJDExPZEBaIgma6bZzCPjNW0HfbDBbWw5/ZW6NtbSA2RE3bbAZXFL6Q/fQltIfYvTfrkhXo4Ailiup8LPlQAmf7y/m8/0+PvummB0HS/EHGv/n1rtbLGekJXJ6eiIDeiZwWs8E+qUmKLh0FpUl5mRyB780g8uBzZD/CVT6mn5Ncp+a1pb0IZB+NiRlanI5kVOYAop0SFXVQXYcLGXLAR9f5pew5YCPrfklFJZUNvmaDG8M/VMT6JcaT06Pmq1XcixOjSTq2IJBc02hgs/M8HJ4BxzZYba4lB1s/DWx3SDtrNB2prml9FP/FpFThAKKdCpHy6rYWlDCtoISvswv4avCUnYeLOVQaVWTr3E5bGR1iyMrJY6slFiyU+LITomjd7c4MpNj6RbnUl+Xjqz8iBlcDnxitrTkfwoHtzYcRRTm8ZpT94e3lBwzuKT0M1tiHGppE+kMFFDklFBUXsWOg6VmYDlUxteHyvj6UDm7DpfVmbK/MTEuO5nJsfRKjiXDG0N6Ugxp4cekGNK9MaTEuTUBXUfir4BDWyH/M3OSuYLPzP4uTbW2hNmdZkhJyoT4VIjvUfOYmGEGGm+W+ryINFcwAEe/BqcHvL2jemkFFDmlBYMGB3wV7D5cxt4j5ew5Us6eI8fYc6Scb44eazDRXFMcdhvd4930SPCQmuihR4KHHoluUhPM590TzGPd4twkx7mIcTna+CeTRlWVmaOJivZA0W44uttcLDG8NTWqqL4YL3izITHNvJUU2w1iU8zHuO4Q390MNnE9zHCj0UdyPMEAYOvccwJV+EL/be2Gwi1mH7LCLXBom/nf1ejb4JLfRfVbtuTzW+2i0unY7TZ6hVpH6N/weIU/QH5xBfuLj7G/qIIDRcfI91VQ4Ksg31dBfnElh8sqCQQNCksqzT4wTQxCqS3O7YiEldqP3eJcdIs3v06Oc5Mcaz52i3ORGOPCoVaak+OON4crp57R8FgwCCX7zaBSWmi2tpQdhLJD5qPvGyjaC8eOQEUxVHwKBZ827/vGdoOEdEistcX3rBVuQpsn0fxL0+kBZwzYFWQ7vWDQ/IAOb1XlZv+pgs/NVr2CL8wP8aDffM+dMeCKM9e2cseDJ8n8dxHevL3MTuDpQ8x/R/VVlkLxXqiuhIQ0Myg3ddsyGDBDe8APgarQ5jdvjzpc4HCbo+ccLnMB0eK9Zqgv2lOzFe81t4ripn8Hzpjmh/82ohYU6ZKqA0GOlFVRWFLJwdJKDvrMx0OllRwurYo8Hi6r5Gi5n0Cw9f+ZJHicJMU4SYxxkRTrxBvrIinWhbfWlhjjIjHGSWKMk6TQ8wSPk4QYJx6nPvBOWvgDoGivGVyOHa21HYHywzWhpvxww5WhW8LmMD+k4lLM1pi47maLTIzXDC82R61Hp3muOx7cCTXPY7xmx+CYZPPDrjP/lR5NAT+UFpireZfmQ0m+2Z/JBtjs5u/UFvpdVZWZo8sqfeZjVZkZIiO/5zhwxpr/Bkrza65ZWti2H8zxPc2g4kmoCQzlh+ueY7ObISUhzay1wmf+HBXFxx8Z1xoxyZCcBakDza3nIPOxW982Cdu6xSMSRYZh4Kuopqi8iqPlfo6WVXE09NzcZz4vLvdztLyKonI/xcf8lFZWR+X7uxw2EjxO4j3OUNipCTMJMU4SPC7i3Q7iPM46j+Hz49wO89HjJM7lUL+bEwkGQh9ahTUfgiX55gdj2UFz5eja4aay5OQCzYnY7OZf4Q6PGWgcTrC7zOfBavOv+EC1+Zd0sDr0F3ytv97dCeYHjRE0J98L12p3mh/YDndN649hhK7jr/kL3eE2r+FJqLmezWa2KviPgT/0GKgKXdswr4NhXqOyFKpKzYBQVWqeGwyEag9t4dpqvzZca+Sawbb9PTfF7jSDTHIW9BxszuvTc7D5Qe5OCP0Oav0eqspqQlGlzwwXR3aancEPbTd/lsbEeM33oOxg839OmyPUYuI235NgtdkKU3sl8/jUUOfyPqHHLPNWZ3KW2b/Ek3jSv6KWUEAR6QD8gSAlFdX4jvnxVfjxHaum+JgZXnwV/sjz4mN+SiqqKamo+1he1cSIlpMU53YQ53YS7zEfza8dxLocxIaex7hCX4f2hb+Oc5tfm8+dxLjsxLgceFx2Yl3meV1yIclAtflXd6AqdEugzPyrONwyU34YKorMD2YjGHoMmB/g4Q+1qlLzQ66yxPxL+VgRVB+z+ifreOxOs2UhMd28BRffHbCZv89IqDFqglpMktkK5Yo1P7yryuqGpdjk0K28NPMxoad5fji0RXOEWFWZ2cfjwGbz30p4VJo3q2YofTBg/psJt+r4y82fIcZb06LmSTBDSVMtHEYoHGKYP0cHooAicgoIBA3KqqopraimrLIaX0U1pZXm17XDTFlVgPKqasoqzcfSSjPclFZWU14ZoKyymtKq6kaXI2gLDruNGKcZXMLhJcZpPnqcdjxOh/noMh/dzrr7zdfVPHqcDtwOOx6XPfRY83XN60PXdNpPreHl/goz2FT4arVshFpNgtWhFhV36DHUquIvD90SKKnZMGpufdjsob+2A6E+FpU1wcpmN1tnHKHN7jKPVZXWtISEbzG44s0PfVecebvE7gpdG8Bmfg+7y/wwdSeGAkOC2RphD93eCm/hmmy2mtdiC30A20LH7WZNMcm65dWJqZOsyCnAYbeRFOMiKebkR5MYhkGFP0hZVSi0VFXXCjUBjvnNUHOsyvy6wh/gmD/0WBU+x/w6fF7kuD9Ahb+mSdoMVoEGq2C3F7ejJrhENof56HLUBCKXo/5+Gy6HPbK5HbbI68Ovc9d6dDV1zchrbHgcDlyh6zrttpaHJ1cMuNIb71gpcopTQBHpAmw2m3lrxu2AhOhf3zAMKquDVITCSoU/QEV1zfOq0LHK6mDkvKrqIFWBIJX+IJXVgcj+2teprA6YxwNBKv2ByPlVtb+uDtZpHaoKmMdp3mjzdmOzUS8UmQHIZbfjdIRCTCgYOe12XE7zec1+M0S564Sg8GarFawaBjOnw3ydMxSU3E47DrsNl92Ow2HDabdFvg7X5mhNoBKJIgUUETlpNpstckunvRmGYYaSanOrjGyByL6qajPkVFUH8QfMzQxIRs2+0GNVwKh7TihIhR/rv7aqOoC/1nVqf6+6dRK5XkcLT42pHajqBKBQgKkfomqO2+oEJ2etABb52m6LhCWnw3zuCu0Lfy+n3YYrFOBcoXPcjlCwCgWo8LXDAaz291W46vwUUESkU7PZbKE+KB1rOLZhGASCRiS8VAbMIOOvF3iqAwbVgZrn/kAQf9A8rzrYMESFX1sZOu6vrnlN7bAUDmjmeeY51bXCV3XQIBg0qA6adVbXG0pfJ1B1QuEgU6eFym7DEdrnCLcaOeoGIGc4fDlqjjvrh6da1zVbn+y1QpN5bvj711yrJpCFw1X4fEc4qNXaX/v71G7latWtwk5KAUVEpA3YbOHWAcxba3TsmWkNw4gEGX+1EblVVl2n9cgMP/UDVfhYdaBeK1S1GZzC+/0Bg+pg0AxEAaNOcKoO1hwPf//qoHks3HLlrzYIGOb1IsEqdLy+QOh4BZ0zYB2Po1ZYCYcZ8xZd3ZYph92Oww4OmxlqHHYbDpsNu50GAcnlbNhaNqJvN753dqZlP6cCioiIYLPZIh9OuK2upmXCrVXVwVCYCbUaVYUew4EqULvFKBSGalqVzK9rv8ZfOzjVeR46JxiMBK1AKGyFW80CwZqWq5p9NV+HXxMI1oS2utc2mpwgMvy6ppdTjY6qQFABRUREpLVqt1adSmtmhW/BBUOtW5HwEmjYklQ/CEWOGeatvEDQIGiEwo1Rc3svGDTwB+u1hoVuG57d22vpz6+AIiIi0gHZ7TbcXXjmZ812IyIiIh2OAoqIiIh0OJYGlCeffJK+ffsSExPDyJEjWbt2rZXliIiISAdhWUD561//yp133smvf/1rNm7cyDnnnMO4ceMoLCy0qiQRERHpICwLKI899hjTp0/nhhtuYPDgwSxatIi4uDieffZZq0oSERGRDsKSgFJVVcWGDRvIzc2tKcRuJzc3l9WrV1tRkoiIiHQglgwzPnToEIFAgLS0tDr709LS+PLLLxucX1lZSWVlzeIVPp+vzWsUERER63SKUTzz58/H6/VGtqysLKtLEhERkTZkSUDp0aMHDoeDgoKCOvsLCgpIT09vcP6cOXMoLi6ObHv37m2vUkVERMQClgQUt9vN8OHDWb58eWRfMBhk+fLljBo1qsH5Ho+HpKSkOpuIiIicuiyb6v7OO+9k6tSpjBgxgvPPP58FCxZQVlbGDTfcYFVJIiIi0kFYFlB+8IMfcPDgQebNm0d+fj7nnnsuS5cubdBxVkRERLoem2EYja/n3IH5fD68Xi/FxcW63SMiItJJtOTzu1OuZhzOVBpuLCIi0nmEP7eb0zbSKQNKSUkJgIYbi4iIdEIlJSV4vd7jntMpb/EEg0H2799PYmIiNpstqtf2+XxkZWWxd+9e3T7qIPSedDx6TzomvS8dj96TugzDoKSkhMzMTOz24w8k7pQtKHa7nd69e7fp99Bw5o5H70nHo/ekY9L70vHoPalxopaTsE4xk6yIiIh0LQooIiIi0uEooNTj8Xj49a9/jcfjsboUCdF70vHoPemY9L50PHpPWq9TdpIVERGRU5taUERERKTDUUARERGRDkcBRURERDocBRQRERHpcBRQannyySfp27cvMTExjBw5krVr11pdUpcxf/58zjvvPBITE+nZsydXXHEFW7durXNORUUFM2fOpHv37iQkJDB58mQKCgosqrjreeihh7DZbMyePTuyT++JNb755ht+9KMf0b17d2JjYxkyZAjr16+PHDcMg3nz5pGRkUFsbCy5ubls377dwopPbYFAgLlz55KTk0NsbCz9+/fnd7/7XZ31ZvSetIIhhmEYxiuvvGK43W7j2WefNT7//HNj+vTpRnJyslFQUGB1aV3CuHHjjOeee8747LPPjE2bNhkTJkwwsrOzjdLS0sg5P/nJT4ysrCxj+fLlxvr1640LLrjAGD16tIVVdx1r1641+vbta5x99tnG7bffHtmv96T9HTlyxOjTp48xbdo0Iy8vz9i5c6fx3nvvGV999VXknIceesjwer3GkiVLjM2bNxuXX365kZOTYxw7dszCyk9dDzzwgNG9e3fjnXfeMXbt2mW89tprRkJCgvH4449HztF70nIKKCHnn3++MXPmzMjXgUDAyMzMNObPn29hVV1XYWGhARgrV640DMMwioqKDJfLZbz22muRc7Zs2WIAxurVq60qs0soKSkxBgwYYCxbtsz49re/HQkoek+s8Ytf/MK48MILmzweDAaN9PR04/e//31kX1FRkeHxeIyXX365PUrsci677DLjxhtvrLPvqquuMqZMmWIYht6T1tItHqCqqooNGzaQm5sb2We328nNzWX16tUWVtZ1FRcXA5CSkgLAhg0b8Pv9dd6jgQMHkp2drfeojc2cOZPLLruszu8e9J5Y5a233mLEiBF8//vfp2fPngwdOpRnnnkmcnzXrl3k5+fXeV+8Xi8jR47U+9JGRo8ezfLly9m2bRsAmzdv5sMPP2T8+PGA3pPW6pSLBUbboUOHCAQCpKWl1dmflpbGl19+aVFVXVcwGGT27NmMGTOGs846C4D8/HzcbjfJycl1zk1LSyM/P9+CKruGV155hY0bN7Ju3boGx/SeWGPnzp089dRT3Hnnnfzyl79k3bp13HbbbbjdbqZOnRr53Tf2/zO9L23jnnvuwefzMXDgQBwOB4FAgAceeIApU6YA6D1pJQUU6XBmzpzJZ599xocffmh1KV3a3r17uf3221m2bBkxMTFWlyMhwWCQESNG8OCDDwIwdOhQPvvsMxYtWsTUqVMtrq5revXVV1m8eDEvvfQSZ555Jps2bWL27NlkZmbqPTkJusUD9OjRA4fD0WD0QUFBAenp6RZV1TXNmjWLd955h/fff5/evXtH9qenp1NVVUVRUVGd8/UetZ0NGzZQWFjIsGHDcDqdOJ1OVq5cyRNPPIHT6SQtLU3viQUyMjIYPHhwnX2DBg1iz549AJHfvf5/1n5+/vOfc88993DttdcyZMgQrr/+eu644w7mz58P6D1pLQUUwO12M3z4cJYvXx7ZFwwGWb58OaNGjbKwsq7DMAxmzZrFG2+8wYoVK8jJyalzfPjw4bhcrjrv0datW9mzZ4/eozYyduxYPv30UzZt2hTZRowYwZQpUyLP9Z60vzFjxjQYgr9t2zb69OkDQE5ODunp6XXeF5/PR15ent6XNlJeXo7dXvfj1OFwEAwGAb0nrWZ1L92O4pVXXjE8Ho/x/PPPG1988YUxY8YMIzk52cjPz7e6tC7hpz/9qeH1eo0PPvjAOHDgQGQrLy+PnPOTn/zEyM7ONlasWGGsX7/eGDVqlDFq1CgLq+56ao/iMQy9J1ZYu3at4XQ6jQceeMDYvn27sXjxYiMuLs74y1/+EjnnoYceMpKTk40333zT+OSTT4xJkyZpSGsbmjp1qtGrV6/IMOPXX3/d6NGjh3H33XdHztF70nIKKLUsXLjQyM7ONtxut3H++ecba9assbqkLgNodHvuueci5xw7dsy45ZZbjG7duhlxcXHGlVdeaRw4cMC6orug+gFF74k13n77beOss84yPB6PMXDgQOPpp5+uczwYDBpz58410tLSDI/HY4wdO9bYunWrRdWe+nw+n3H77bcb2dnZRkxMjNGvXz/jV7/6lVFZWRk5R+9Jy9kMo9ZUdyIiIiIdgPqgiIiISIejgCIiIiIdjgKKiIiIdDgKKCIiItLhKKCIiIhIh6OAIiIiIh2OAoqIiIh0OAooIiIi0uEooIiIiEiHo4AiIiIiHY4CioiIiHQ4CigiIiLS4fz/VOOsvhppQOcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Training Loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_e, label= 'train')\n",
    "plt.plot(test_e, label = 'test')\n",
    "plt.legend()\n",
    "print(min(test_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tag(sample):\n",
    "    sample = [vocab_clean(word) for word in sample]\n",
    "    length = [len(sample)]\n",
    "\n",
    "    ini = np.zeros((1,MAX_LEN,NUM_COMPONENTS))\n",
    "    vector_sample = np.array([ wv_from_bin[i] for i in sample])\n",
    "    vector_sample = vector_sample\n",
    "    ini[0,:vector_sample.shape[0],:NUM_COMPONENTS] = vector_sample\n",
    "    sample = torch.tensor(ini).to(device).type(torch.cuda.FloatTensor)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    model.eval()        \n",
    "    y_pred = model.forward(sample, length)\n",
    "    y_pred =y_pred.view(1,  MAX_LEN, CAT_NUM,-1)\n",
    "    y_pred = y_pred.cpu()\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    y_pred = y_pred[0]\n",
    "    y_pred = y_pred.squeeze()\n",
    "    y_pred = y_pred.argmax(axis = 1)\n",
    "    out_list = []\n",
    "    for i in y_pred:\n",
    "        if target_name_to_index[i] != '[PAD]':\n",
    "            out_list.append(target_name_to_index[i])\n",
    "        else:\n",
    "            break\n",
    "    return out_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'women', \"'s\", 'handbag']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(title):\n",
    "    tokens = title.split(' ')\n",
    "    out = []\n",
    "    for token in tokens:\n",
    "        out.append(token)\n",
    "    return out\n",
    "\n",
    "tokenizer(\"the women 's handbag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\r"
     ]
    }
   ],
   "source": [
    "submission = {'Record number':[], \"Aspect Name\":[], \"Aspect Value\":[]}\n",
    "for num in range(5001,30001):\n",
    "    print(int(((num-5000)/(30000-5000))*100), end = '\\r')\n",
    "    tokens = tokenizer(df_title['Title'][num-1])\n",
    "\n",
    "    out_list=predict_tag(tokens)\n",
    "    temp=None\n",
    "    jump = False\n",
    "    for i in range(min(len(out_list),len(tokens))):\n",
    "        # if tokens[i] == 'strap' or tokens[i] == 'strapdrop':\n",
    "            # found = False\n",
    "            # index = i\n",
    "            # while index != 0:\n",
    "            #     if tokens[index].isnumeric():\n",
    "            #         submission['Record number'].append(num)\n",
    "            #         submission['Aspect Name'].append('Strap Drop')\n",
    "            #         submission['Aspect Value'].append(tokens[i])                    \n",
    "            #         found = True\n",
    "            #         break\n",
    "            #     index-=1\n",
    "            # if found:\n",
    "            #     continue\n",
    "        if jump:\n",
    "            jump = False \n",
    "            continue\n",
    "        if tokens[i].lower() == 'hand' and i != len(tokens)-1 and   tokens[i+1].lower() == 'bag':\n",
    "            jump = True\n",
    "            submission['Record number'].append(num)\n",
    "            submission['Aspect Name'].append('Type')\n",
    "            submission['Aspect Value'].append(tokens[i] + ' ' + tokens[i+1])\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        if tokens[i].lower() == 'cc' and i != len(tokens)-1 and   tokens[i+1].lower() == 'logo':\n",
    "            jump = True\n",
    "            submission['Record number'].append(num)\n",
    "            submission['Aspect Name'].append('Accents')\n",
    "            submission['Aspect Value'].append(tokens[i] + ' ' + tokens[i+1])\n",
    "            continue\n",
    "        if tokens[i].lower() == 'leather' and i != 0 and   out_list[i-1] == 'Material':\n",
    "            submission['Aspect Value'][-1] = tokens[i-1] + ' ' + tokens[i]\n",
    "            continue\n",
    "        if out_list[i] == temp and (out_list[i] == 'Model' or\n",
    "                                    out_list[i] == 'Brand' or \n",
    "                                    out_list[i] == 'Theme' or\n",
    "                                    out_list[i] == 'Trim Material' or\n",
    "                                    out_list[i] == 'Strap Drop' or \n",
    "                                    out_list[i] == 'Character' or\n",
    "                                    out_list[i] == 'Character Family' or\n",
    "                                    out_list[i] == 'Features' or\n",
    "                                    out_list[i] == 'Handle Drop' or\n",
    "                                    out_list[i] == 'Shoulder Strap' or\n",
    "                                    out_list[i] == 'Hardware Material' or\n",
    "                                    out_list[i] =='Handle Style' or\n",
    "                                    out_list[i] =='Measurement, dimension' or\n",
    "                                    out_list[i] == 'Pocket Type' or\n",
    "                                    out_list[i] == 'Product Line'):\n",
    "            prev_name = submission['Aspect Value'][-1]\n",
    "            submission['Record number'].append(num)\n",
    "            # submission['Aspect Name'].append(out_list[i])\n",
    "            submission['Aspect Value'][-1] = prev_name + ' ' + tokens[i]\n",
    "        else:\n",
    "            submission['Record number'].append(num)\n",
    "            submission['Aspect Name'].append(out_list[i])\n",
    "            submission['Aspect Value'].append(tokens[i])\n",
    "            temp = out_list[i]\n",
    "submission= pd.DataFrame(submission)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\r"
     ]
    }
   ],
   "source": [
    "submission = {'Record number':[], \"Aspect Name\":[], \"Aspect Value\":[]}\n",
    "for num in range(5001,30000):\n",
    "    print(int(((num-5000)/(30000-5000))*100), end = '\\r')\n",
    "    tokens = tokenizer(df_title['Title'][num-1])\n",
    "\n",
    "    out_list=predict_tag(tokens)\n",
    "    temp=None\n",
    "    for i in range(min(len(out_list),len(tokens))):\n",
    "            submission['Record number'].append(num)\n",
    "            submission['Aspect Name'].append(out_list[i])\n",
    "            submission['Aspect Value'].append(tokens[i])\n",
    "            temp = out_list[i]\n",
    "submission= pd.DataFrame(submission)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', sep ='\\t', index = False,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result showcase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ladies Rowallan Soft Tan Real Leather Over Body / shoulder Bag\n",
      "['Ladies', 'Rowallan', 'Soft', 'Tan', 'Real', 'Leather', 'Over', 'Body', '/', 'shoulder', 'Bag']\n",
      "['Department', 'Model', 'Features', 'Color', 'No Tag', 'Material', 'Closure', 'Type', 'No Tag', 'Type', 'Type']\n"
     ]
    }
   ],
   "source": [
    "num = 280021\n",
    "print(df_title['Title'][num])\n",
    "tokens = tokenizer(df_title['Title'][num])\n",
    "\n",
    "print(tokens)\n",
    "out_list=predict_tag(tokens)\n",
    "print(out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record number</th>\n",
       "      <th>Aspect Name</th>\n",
       "      <th>Aspect Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>5248</td>\n",
       "      <td>Strap Drop</td>\n",
       "      <td>strap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103758</th>\n",
       "      <td>21461</td>\n",
       "      <td>Strap Drop</td>\n",
       "      <td>strap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120985</th>\n",
       "      <td>24208</td>\n",
       "      <td>Strap Drop</td>\n",
       "      <td>strap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145899</th>\n",
       "      <td>28092</td>\n",
       "      <td>Strap Drop</td>\n",
       "      <td>strap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Record number Aspect Name Aspect Value\n",
       "1454             5248  Strap Drop        strap\n",
       "103758          21461  Strap Drop        strap\n",
       "120985          24208  Strap Drop        strap\n",
       "145899          28092  Strap Drop        strap"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ = submission[submission['Aspect Name']=='Strap Drop']\n",
    "test_.to_csv('test.csv')\n",
    "test_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1aaefd176c54b5c3e652479d69d1e0f261a4b163a6bec681fd43e0c16921b5a0"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
